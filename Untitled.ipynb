{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9bcfca-a948-4742-b96f-d4a009d73136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a5d896-8ccd-4c49-9b65-93c8f0aff6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankitsharma_ds1/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ankitsharma_ds1/.venv/lib/python3.12/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for VertexAIEmbeddings\n  Value error, Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project [type=value_error, input_value={'project': '', 'location... 'default_metadata': ()}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m BATCH_LLM_SIZE = \u001b[38;5;28mint\u001b[39m(os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mBATCH_LLM_SIZE\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m20\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     30\u001b[39m LLM_INNER_BATCH = \u001b[38;5;28mint\u001b[39m(os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mLLM_INNER_BATCH\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m5\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m extractor = \u001b[43mHealthcareStoryExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROJECT_ID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Run extraction\u001b[39;00m\n\u001b[32m     35\u001b[39m stories = \u001b[38;5;28;01mawait\u001b[39;00m  extractor.extract_from_file(\n\u001b[32m     36\u001b[39m         FILE_PATH,\n\u001b[32m     37\u001b[39m         dedupe=DEDUPE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m \n\u001b[32m     43\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/healthcare-test-case-generation-with-ai-h2s-hackathon/src/requirement_builder.py:390\u001b[39m, in \u001b[36mHealthcareStoryExtractor.__init__\u001b[39m\u001b[34m(self, project_id, location, embedding_model, classifier_model)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28mself\u001b[39m.project_id = project_id\n\u001b[32m    389\u001b[39m \u001b[38;5;28mself\u001b[39m.location = location\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m \u001b[38;5;28mself\u001b[39m.embedder = \u001b[43mVertexAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28mself\u001b[39m.llm = VertexAI(\n\u001b[32m    396\u001b[39m     model_name=classifier_model,\n\u001b[32m    397\u001b[39m     temperature=\u001b[32m0.2\u001b[39m,   \u001b[38;5;66;03m# slight diversity, still stable JSON\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    401\u001b[39m     location=location,\n\u001b[32m    402\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/langchain_google_vertexai/embeddings.py:176\u001b[39m, in \u001b[36mVertexAIEmbeddings.__init__\u001b[39m\u001b[34m(self, model_name, project, location, request_parallelism, max_retries, credentials, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_name:\n\u001b[32m    175\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m] = model_name\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest_parallelism\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_parallelism\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28mself\u001b[39m.instance[\u001b[33m\"\u001b[39m\u001b[33mmax_batch_size\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mmax_batch_size\u001b[39m\u001b[33m\"\u001b[39m, _MAX_BATCH_SIZE)\n\u001b[32m    185\u001b[39m \u001b[38;5;28mself\u001b[39m.instance[\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.instance[\u001b[33m\"\u001b[39m\u001b[33mmax_batch_size\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for VertexAIEmbeddings\n  Value error, Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project [type=value_error, input_value={'project': '', 'location... 'default_metadata': ()}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "LLM_MODEL = \"gemini-2.0-flash\"  # e.g., \"gemini-1.5-pro\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import asyncio\n",
    "import docx\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from PyPDF2 import PdfReader\n",
    "from typing import List, Iterable, Dict, Any, Optional\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from src.requirement_builder import HealthcareStoryExtractor\n",
    "from google.cloud import bigquery\n",
    "from langchain_google_vertexai import VertexAIEmbeddings, VertexAI\n",
    "# Auto-detect project from your auth context\n",
    "bq_client = bigquery.Client()\n",
    "PROJECT_ID = bq_client.project\n",
    "TEST = True   # set this to False for full run\n",
    "\n",
    "# Configs (override via env)\n",
    "FILE_PATH = os.environ.get(\"INPUT_FILE\", \"data/srs.pdf\")\n",
    "OUTPUT_JSON = os.environ.get(\"OUTPUT_JSON\", \"generated_user_stories.json\")\n",
    "DEDUPE = os.environ.get(\"DEDUPE\", \"true\").lower() in {\"1\", \"true\", \"yes\"}\n",
    "DUP_THRESHOLD = float(os.environ.get(\"DUP_THRESHOLD\", \"0.99\"))\n",
    "EXPORT = os.environ.get(\"EXPORT_TO_BQ\", \"false\").lower() in {\"1\", \"true\", \"yes\"}\n",
    "BATCH_LLM_SIZE = int(os.environ.get(\"BATCH_LLM_SIZE\", \"20\"))\n",
    "LLM_INNER_BATCH = int(os.environ.get(\"LLM_INNER_BATCH\", \"5\"))\n",
    "\n",
    "extractor = HealthcareStoryExtractor(project_id=PROJECT_ID)\n",
    "\n",
    "# Run extraction\n",
    "stories = await  extractor.extract_from_file(\n",
    "        FILE_PATH,\n",
    "        dedupe=DEDUPE,\n",
    "        dup_threshold=DUP_THRESHOLD,\n",
    "        batch_llm_size=BATCH_LLM_SIZE,\n",
    "        llm_inner_batch=LLM_INNER_BATCH,\n",
    "    TEST=TEST\n",
    "    \n",
    "    )\n",
    "# Save test cases to CSV\n",
    "# export_testcases_csv(stories, extractor._last_requirements, out_csv=\"testcases.csv\")\n",
    "\n",
    "\n",
    "# Save to JSON\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(stories, f, indent=2, ensure_ascii=False)\n",
    "print(f\"✅ Extracted user stories saved to {OUTPUT_JSON}\")\n",
    "\n",
    "import json\n",
    "\n",
    "# Save segmented requirements\n",
    "with open(\"requirements.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(extractor._last_requirements, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Save generated user stories\n",
    "with open(\"stories.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(stories, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Saved requirements.json and stories.json\")\n",
    "\n",
    "# Optional: export to BigQuery\n",
    "# if EXPORT:\n",
    "#     extractor.export_to_bq(stories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc1868a-6185-4ba9-8f48-bd17d02002a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stories_file = \"outputs/stories.json\"\n",
    "\n",
    "with open(stories_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    stories = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00564258-6777-4604-b13b-f4b73d19c638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Wrote 4 Gherkin feature file(s) to features\n",
      "🧩 Wrote step stubs for pytest-bdd to steps/test_steps_bdd.py\n",
      "📊 Wrote RTM to traceability.csv (12 rows)\n",
      "✅ All requirements have at least one scenario.\n"
     ]
    }
   ],
   "source": [
    "from src.testcase_generator import TestCaseGenerator\n",
    "\n",
    "tcgen = TestCaseGenerator()\n",
    "result = tcgen.generate(\n",
    "    stories,\n",
    "    feature_dir=\"features\",\n",
    "    steps_dir=\"steps\",\n",
    "    framework=\"pytest-bdd\",     # or \"behave\"\n",
    "    feature_per_epic=True,\n",
    "    traceability_csv=\"traceability.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79783e62-3230-457e-8a38-1e37bd782103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗂️  Wrote Jira-friendly CSV to jira_testcases.csv\n",
      "🗂️  Wrote ADO-friendly CSV to ado_testcases.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('ado_testcases.csv')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolchain_connector import ToolChainConnector\n",
    "# Create an instance of the class\n",
    "connector = ToolChainConnector()\n",
    "\n",
    "# Use the methods to export the data\n",
    "connector.export_to_jira_csv(\n",
    "    stories,\n",
    "    path=\"jira_testcases.csv\",\n",
    "    project_key=\"\",\n",
    "    default_labels=[\"auto-generated\", \"vertex-ai\", \"traceable\"],\n",
    "    test_type=\"Manual\",\n",
    ")\n",
    "\n",
    "connector.export_to_ado_csv(\n",
    "    stories,\n",
    "    path=\"ado_testcases.csv\",\n",
    "    area_path=\"Healthcare\\\\DayHealth\",\n",
    "    iteration_path=\"Release 1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee73cc8b-a287-4122-9518-dd4f98c71fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Data loaded successfully.\n",
      "✅ Requirement-level coverage: coverage_matrix.csv\n",
      "✅ Epic-level rollup: epic_coverage.csv\n"
     ]
    }
   ],
   "source": [
    "from coverage_analyser import CoverageAnalyzer\n",
    "\n",
    "# Use the class\n",
    "analyzer = CoverageAnalyzer(\n",
    "    requirements_path=\"requirements.json\",\n",
    "    stories_path=\"stories.json\",\n",
    "    testcases_path=\"testcases.csv\"\n",
    ")\n",
    "\n",
    "# Run the full analysis\n",
    "analyzer.run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81c19a32-e9e3-4d5a-811d-3542d82eed9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'testcases.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcompliance_validator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_compliance_report\n\u001b[0;32m----> 2\u001b[0m compliance_report\u001b[38;5;241m=\u001b[39m\u001b[43mbuild_compliance_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstories_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstories.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtestcases_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtestcases.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompliance_evidence.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_xlsx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompliance_evidence.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPROJECT_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/healthcare-test-case-generation-with-ai-h2s-hackathon/compliance_validator.py:242\u001b[0m, in \u001b[0;36mbuild_compliance_report\u001b[0;34m(stories_path, testcases_path, out_csv, out_xlsx, project_id, location, use_embeddings)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'testcases.csv'"
     ]
    }
   ],
   "source": [
    "from compliance_validator import \n",
    "compliance_report=build_compliance_report(\n",
    "    stories_path=\"stories.json\",\n",
    "    testcases_path=\"testcases.csv\",\n",
    "    out_csv=\"compliance_evidence.csv\",\n",
    "    out_xlsx=\"compliance_evidence.xlsx\",\n",
    "    project_id=PROJECT_ID,\n",
    "    use_embeddings=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1458f1a-8d9d-4683-990e-2cdd10919927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Requirement ID</th>\n",
       "      <th>Story Id</th>\n",
       "      <th>Epic</th>\n",
       "      <th>Priority</th>\n",
       "      <th>User Story</th>\n",
       "      <th>Pages (Citations)</th>\n",
       "      <th>Alignment Score</th>\n",
       "      <th>Needs Review</th>\n",
       "      <th>Matched Clauses</th>\n",
       "      <th>Clause Scores</th>\n",
       "      <th>Expected Controls</th>\n",
       "      <th>Detected Controls</th>\n",
       "      <th>Missing Controls</th>\n",
       "      <th>Evidence (Story + Steps)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTO-1</td>\n",
       "      <td>cde5b225-2357-4adb-93ec-da487789af32</td>\n",
       "      <td></td>\n",
       "      <td>Must</td>\n",
       "      <td>As a Doctor, I want to access patient informat...</td>\n",
       "      <td>13;1</td>\n",
       "      <td>0.286</td>\n",
       "      <td>False</td>\n",
       "      <td>FDA 21 CFR Part 11 11.10(e); ISO 13485 4.2.5; ...</td>\n",
       "      <td>0.546; 0.544; 0.537; 0.503</td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td></td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td>As a Doctor, I want to access patient informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>e38976ef-ecde-4dad-be96-946e70ee23c5</td>\n",
       "      <td>Digitize patient records and automate tracking.</td>\n",
       "      <td>Must</td>\n",
       "      <td>As a Nurse, I want to access digitized patient...</td>\n",
       "      <td>4;4;6</td>\n",
       "      <td>0.449</td>\n",
       "      <td>False</td>\n",
       "      <td>FDA 21 CFR Part 11 11.10(e); FDA 21 CFR Part 1...</td>\n",
       "      <td>0.649; 0.618; 0.609; 0.574</td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td></td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td>As a Nurse, I want to access digitized patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4</td>\n",
       "      <td>84a207e5-df27-4209-b80b-2fceaac9c3f0</td>\n",
       "      <td>Replace Trillium's current system with a new s...</td>\n",
       "      <td>Must</td>\n",
       "      <td>As a Doctor, I want to view patient data store...</td>\n",
       "      <td>5;6</td>\n",
       "      <td>0.166</td>\n",
       "      <td>False</td>\n",
       "      <td>FDA 21 CFR Part 11 11.10(e); ISO 13485 4.2.5; ...</td>\n",
       "      <td>0.633; 0.602; 0.6; 0.568</td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td></td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td>As a Doctor, I want to view patient data store...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>fbaab98c-274f-47c7-82cc-759b1def04a7</td>\n",
       "      <td></td>\n",
       "      <td>Must</td>\n",
       "      <td>As a Doctor, I want to view audit history repo...</td>\n",
       "      <td>8;8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "      <td>FDA 21 CFR Part 11 11.10(e); ISO 13485 4.2.5; ...</td>\n",
       "      <td>0.711; 0.646; 0.601; 0.593</td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td></td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td>As a Doctor, I want to view audit history repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ab2d2e4b-4c15-4556-8c51-fe1916d29d7a</td>\n",
       "      <td></td>\n",
       "      <td>Must</td>\n",
       "      <td>As a Day Health staff member, I want to digiti...</td>\n",
       "      <td>4;4;4</td>\n",
       "      <td>0.024</td>\n",
       "      <td>True</td>\n",
       "      <td>ISO 13485 4.2.5; FDA 21 CFR Part 11 11.10(e); ...</td>\n",
       "      <td>0.557; 0.552; 0.525; 0.519</td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td></td>\n",
       "      <td>audit_trail; data_integrity; e_signature; rbac...</td>\n",
       "      <td>As a Day Health staff member, I want to digiti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Requirement ID                              Story Id  \\\n",
       "0         AUTO-1  cde5b225-2357-4adb-93ec-da487789af32   \n",
       "1            1.1  e38976ef-ecde-4dad-be96-946e70ee23c5   \n",
       "2            1.4  84a207e5-df27-4209-b80b-2fceaac9c3f0   \n",
       "3              2  fbaab98c-274f-47c7-82cc-759b1def04a7   \n",
       "4              1  ab2d2e4b-4c15-4556-8c51-fe1916d29d7a   \n",
       "\n",
       "                                                Epic Priority  \\\n",
       "0                                                        Must   \n",
       "1    Digitize patient records and automate tracking.     Must   \n",
       "2  Replace Trillium's current system with a new s...     Must   \n",
       "3                                                        Must   \n",
       "4                                                        Must   \n",
       "\n",
       "                                          User Story Pages (Citations)  \\\n",
       "0  As a Doctor, I want to access patient informat...              13;1   \n",
       "1  As a Nurse, I want to access digitized patient...             4;4;6   \n",
       "2  As a Doctor, I want to view patient data store...               5;6   \n",
       "3  As a Doctor, I want to view audit history repo...               8;8   \n",
       "4  As a Day Health staff member, I want to digiti...             4;4;4   \n",
       "\n",
       "   Alignment Score  Needs Review  \\\n",
       "0            0.286         False   \n",
       "1            0.449         False   \n",
       "2            0.166         False   \n",
       "3            0.000          True   \n",
       "4            0.024          True   \n",
       "\n",
       "                                     Matched Clauses  \\\n",
       "0  FDA 21 CFR Part 11 11.10(e); ISO 13485 4.2.5; ...   \n",
       "1  FDA 21 CFR Part 11 11.10(e); FDA 21 CFR Part 1...   \n",
       "2  FDA 21 CFR Part 11 11.10(e); ISO 13485 4.2.5; ...   \n",
       "3  FDA 21 CFR Part 11 11.10(e); ISO 13485 4.2.5; ...   \n",
       "4  ISO 13485 4.2.5; FDA 21 CFR Part 11 11.10(e); ...   \n",
       "\n",
       "                Clause Scores  \\\n",
       "0  0.546; 0.544; 0.537; 0.503   \n",
       "1  0.649; 0.618; 0.609; 0.574   \n",
       "2    0.633; 0.602; 0.6; 0.568   \n",
       "3  0.711; 0.646; 0.601; 0.593   \n",
       "4  0.557; 0.552; 0.525; 0.519   \n",
       "\n",
       "                                   Expected Controls Detected Controls  \\\n",
       "0  audit_trail; data_integrity; e_signature; rbac...                     \n",
       "1  audit_trail; data_integrity; e_signature; rbac...                     \n",
       "2  audit_trail; data_integrity; e_signature; rbac...                     \n",
       "3  audit_trail; data_integrity; e_signature; rbac...                     \n",
       "4  audit_trail; data_integrity; e_signature; rbac...                     \n",
       "\n",
       "                                    Missing Controls  \\\n",
       "0  audit_trail; data_integrity; e_signature; rbac...   \n",
       "1  audit_trail; data_integrity; e_signature; rbac...   \n",
       "2  audit_trail; data_integrity; e_signature; rbac...   \n",
       "3  audit_trail; data_integrity; e_signature; rbac...   \n",
       "4  audit_trail; data_integrity; e_signature; rbac...   \n",
       "\n",
       "                            Evidence (Story + Steps)  \n",
       "0  As a Doctor, I want to access patient informat...  \n",
       "1  As a Nurse, I want to access digitized patient...  \n",
       "2  As a Doctor, I want to view patient data store...  \n",
       "3  As a Doctor, I want to view audit history repo...  \n",
       "4  As a Day Health staff member, I want to digiti...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compliance_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44430a34-2161-43a6-b5f1-81f0fba37b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m132",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m132"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
